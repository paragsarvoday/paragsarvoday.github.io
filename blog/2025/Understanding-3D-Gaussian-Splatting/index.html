<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Understanding 3D Gaussian Splatting | Parag Sarvoday Sahu </title> <meta name="author" content="Parag Sarvoday Sahu"> <meta name="description" content="an attempt to cover the knowledge gap"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%8C%85&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://paragsarvoday.github.io/blog/2025/Understanding-3D-Gaussian-Splatting/"> <script src="/assets/js/theme.js?6ddb66544c57e17a63e7abf8cc6c43e3"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> <link defer rel="stylesheet" href="https://cdn.jsdelivr.net/npm/leaflet@1.9.4/dist/leaflet.min.css" integrity="sha256-q9ba7o845pMPFU+zcAll8rv+gC+fSovKsOoNQ6cynuQ=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@11.9.0/styles/github.min.css" integrity="sha256-Oppd74ucMR5a5Dq96FxjEzGF7tTw2fZ/6ksAqDCM8GY=" crossorigin="anonymous" media="screen and (prefers-color-scheme: light)"> <link defer rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@11.9.0/styles/github-dark.min.css" integrity="sha256-nyCNAiECsdDHrr/s2OQsp5l9XeY2ZJ0rMepjCT2AkBk=" crossorigin="anonymous" media="screen and (prefers-color-scheme: dark)"> <link defer rel="stylesheet" href="https://cdn.jsdelivr.net/npm/diff2html@3.4.47/bundles/css/diff2html.min.css" integrity="sha256-IMBK4VNZp0ivwefSn51bswdsrhk0HoMTLc2GqFHFBXg=" crossorigin="anonymous"> <link defer rel="stylesheet" type="text/css" href="https://tikzjax.com/v1/fonts.css"> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> <style type="text/css">.fake-img{background:#bbb;border:1px solid rgba(0,0,0,0.1);box-shadow:0 0 4px rgba(0,0,0,0.1);margin-bottom:12px}.fake-img p{font-family:monospace;color:white;text-align:left;margin:12px 0;text-align:center;font-size:16px}</style> </head> <body> <d-front-matter> <script async type="text/json">
      {
            "title": "Understanding 3D Gaussian Splatting",
            "description": "an attempt to cover the knowledge gap",
            "published": "August 30, 2025",
            "authors": [
              
              {
                "author": "Parag Sarvoday Sahu",
                "authorURL": "",
                "affiliations": [
                  {
                    "name": "IIT Gandhinagar, India",
                    "url": ""
                  }
                ]
              }
              
            ],
            "katex": {
              "delimiters": [
                {
                  "left": "$",
                  "right": "$",
                  "display": false
                },
                {
                  "left": "$$",
                  "right": "$$",
                  "display": true
                }
              ]
            }
          }
    </script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Parag</span> Sarvoday Sahu </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/books/">bookshelf </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item"> <a class="nav-link" href="/assets/pdf/cv_parag.pdf">cv </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>Understanding 3D Gaussian Splatting</h1> <p>an attempt to cover the knowledge gap</p> </d-title> <d-byline></d-byline> <d-article> <h2 id="what-exactly-is-this-technique">What exactly is this technique?</h2> <p>3D Gaussian Splatting is one of the solutions to the <strong>Novel View Synthesis</strong> problem.</p> <p>Novel View Synthesis? That seems quite complicated, I don’t think this is my cup of tea.</p> <p>Well, don’t stop reading just yet. Its not as contrived as it seems at first glance. Let’s start by understanding the literal meaning of the term ‘Novel View Synthesis’. It is made up of <em>novel</em> which means <em>new</em>, view is quite self-explanatory and <em>synthesis</em> means <em>to combine different elements to make something new</em>. So, the process goes something like this, we have a bunch of pictures of a room (say) and now we want to view the room from angles which were not present in the original set of pictures. To fulfill this desire of ours, we need to <em>synthesize</em> (make) these <em>novel</em> (new) views.</p> <p>Now, there had been many attempts to solve the Novel View Synthesis problem but none of the attempts made for a convincing solution until 3D Gaussian Splatting (3DGS) appeared in 2023. Let’s understand how it works!</p> <h2 id="foundation">Foundation</h2> <p>Before moving to the actual workings of 3DGS, let’s lay a firm foundational knowledge about gaussians.</p> <h3 id="1d-gaussian-function">1D Gaussian function</h3> <p>Starting off with 1D gaussian function, its general form is given as:</p> \[g(x) = \frac{1}{\sigma \sqrt{2\pi}} \exp \left( -\frac{1}{2} \frac{(x - \mu)^2}{\sigma^2} \right)\] <p>Here, $\sigma$ is the spread of the gaussian and $\mu$ is the centre value of it. We query the function by substituting a value in place of the variable $x$.</p> <p>Check out the visualisation below for a better understanding:</p> <div class="row mt-3"> <div class="col-12 mx-auto mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/3dgs_blog/1dgs-480.webp 480w,/assets/img/3dgs_blog/1dgs-800.webp 800w,/assets/img/3dgs_blog/1dgs-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/3dgs_blog/1dgs.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> A 1D gaussian function </div> <details><summary>An interesting detail about 1D gaussians</summary> <p>Gaussian functions arise by composing the exponential function with a concave quadratic function (downward facing parabola)</p> \[f(x) = \exp(\alpha x^2 + \beta x + \gamma)\] <p>where \(\alpha = -\frac{1}{2\sigma^2}, \quad \beta = \frac{\mu}{\sigma^2}, \quad \gamma = -\frac{\mu^2}{2\sigma^2} - \ln(\sigma \sqrt{2\pi})\)</p> </details> <h3 id="2d-gaussian-function">2D Gaussian function</h3> <p>The 2D Gaussian function in our familiar form would look something like:</p> \[g(x, y) = A \exp \left( - \left( \frac{(x - \mu_x)^2}{2\sigma_X^2} + \frac{(y - \mu_y)^2}{2\sigma_Y^2} \right) \right)\] <p>Here, $A$ is the amplitude, $\mu_x$, $\mu_y$ are the centers, and $\sigma_X$, $\sigma_Y$ are the spreads of the 2D gaussian in the $X$ and $Y$ axes respectively.</p> <p>Again, a visualisation to help form a mental picture:</p> <div class="row mt-3"> <div class="col-12 mx-auto mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/3dgs_blog/2dgs_final-480.webp 480w,/assets/img/3dgs_blog/2dgs_final-800.webp 800w,/assets/img/3dgs_blog/2dgs_final-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/3dgs_blog/2dgs_final.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> A 2D gaussian function </div> <p>Notice that a 2D Gaussian is built by stacking ellipses on top of each other. The set of 2D points which result in the same output when plugged in the 2D Gaussian function lie on the same ellipse.</p> <p>So, when a 2D Gaussian is sliced with a plane parallel to the $XY$ plane, we get an ellipse.</p> <h3 id="3d-gaussian-function">3D Gaussian function</h3> <p>As a natural extension to the 2D Gaussian’s definition, we get to the 3D Gaussian function which is given as:</p> \[g(x, y, z) = A \cdot \exp\left( -\frac{1}{2} \left( \frac{(x - \mu_x)^2}{\sigma_x^2} + \frac{(y - \mu_y)^2}{\sigma_y^2} + \frac{(z - \mu_z)^2}{\sigma_z^2} \right) \right)\] <p>An alternate definition of a 3D Gaussian that is often seen in various place (eg. the 3DGS paper!) goes like:</p> \[f(x, y, z) = A \cdot \exp\left( -\frac{1}{2} (\mathbf{r} - \boldsymbol{\mu})^\top \Sigma^{-1} (\mathbf{r} - \boldsymbol{\mu}) \right)\] <p>where:</p> <p>$A = (2\pi)^{-3/2} \det(\Sigma)^{-1/2}$ is the normalization constant</p> <p>$\mathbf{r} = [x, y, z]^\top$ is the position vector</p> <p>$\boldsymbol{\mu} = [\mu_x, \mu_y, \mu_z]^\top$ is the center of the Gaussian</p> <p>$\Sigma^{-1}$ is the inverse of the covariance matrix</p> <details><summary>How can these two definitions be equivalent?</summary> <p>I won’t give out a formal proof to establish their equivalence, but here’s a simple example to build an intuition about it.</p> <p>We take $\Sigma$ to be a diagonal matrix:</p> \[\Sigma = \begin{bmatrix} \sigma_x^2 &amp; 0 &amp; 0 \\ 0 &amp; \sigma_y^2 &amp; 0 \\ 0 &amp; 0 &amp; \sigma_z^2 \end{bmatrix}\] <p>then</p> <p>then \(\Sigma^{-1} = \begin{bmatrix} \frac{1}{\sigma_x^2} &amp; 0 &amp; 0 \\ 0 &amp; \frac{1}{\sigma_y^2} &amp; 0 \\ 0 &amp; 0 &amp; \frac{1}{\sigma_z^2} \end{bmatrix}\)</p> <p>because for a diagonal matrix, the inverse is simply the reciprocal of each of the diagonal elements.</p> <p>expanding $(\mathbf{r} - \boldsymbol{\mu})^\top \Sigma^{-1} (\mathbf{r} - \boldsymbol{\mu})$, we substitute $\mathbf{r} = [x, y, z]^\top$ and $\boldsymbol{\mu} = [\mu_x, \mu_y, \mu_z]^\top$</p> <p>we get:</p> \[(\mathbf{r} - \boldsymbol{\mu}) = \begin{bmatrix} x - \mu_x \\ y - \mu_y \\ z - \mu_z \end{bmatrix}\] \[\Sigma^{-1} (\mathbf{r} - \boldsymbol{\mu}) = \begin{bmatrix} \frac{1}{\sigma_1^2} &amp; 0 &amp; 0 \\ 0 &amp; \frac{1}{\sigma_2^2} &amp; 0 \\ 0 &amp; 0 &amp; \frac{1}{\sigma_3^2} \end{bmatrix} \begin{bmatrix} x - \mu_x \\ y - \mu_y \\ z - \mu_z \end{bmatrix} = \begin{bmatrix} \frac{x - \mu_x}{\sigma_x^2} \\ \frac{y - \mu_y}{\sigma_y^2} \\ \frac{z - \mu_z}{\sigma_z} \end{bmatrix}\] <p>now, \((\mathbf{r} - \boldsymbol{\mu})^\top \begin{bmatrix} \frac{(x - \mu_x)}{\sigma_x^2} \\ \frac{(y - \mu_y)}{\sigma_y^2} \\ \frac{(z - \mu_z)}{\sigma_z^2} \end{bmatrix} = \frac{(x - \mu_x)^2}{\sigma_x^2} + \frac{(y - \mu_y)^2}{\sigma_y^2} + \frac{(z - \mu_z)^2}{\sigma_z^2}\)</p> <p>which looks like the term inside the exponential!</p> </details> <details><summary>Equation for N-dimensional Gaussian function</summary> \[f(\mathbf{x}) = \frac{1}{(2\pi)^{N/2} |\boldsymbol{\Sigma}|^{1/2}} \exp\left(-\frac{1}{2} (\mathbf{x} - \boldsymbol{\mu})^\mathsf{T} \boldsymbol{\Sigma}^{-1} (\mathbf{x} - \boldsymbol{\mu})\right)\] <p>Here, $\mathbf{x}$ will belong to $\mathbb{R}^{N}$ and $\boldsymbol{\Sigma}$ will be of dimension $N \times N$</p> </details> <p>For 3D Gaussian, the $\Sigma$ matrix would look something like this:</p> \[\Sigma = \begin{bmatrix} \sigma_{xx} &amp; \sigma_{xy} &amp; \sigma_{xz} \\ \sigma_{xy} &amp; \sigma_{yy} &amp; \sigma_{yz} \\ \sigma_{xz} &amp; \sigma_{yz} &amp; \sigma_{zz} \end{bmatrix}\] <p>where:</p> <ul> <li>the diagonal elements $(\sigma_{xx}$, $\sigma_{yy}$, $\sigma_{zz})$ represent the variances along the $x$, $y$ and $z$ axes.</li> <li>the off-diagonal elements $(\sigma_{xy}, \sigma_{xz}, \sigma_{yz})$ represent covariances between pairs of axes $(x, y, z)$.</li> </ul> <p>A 3D Gaussian cannot be visualised the way we did for the other two lower dimensional Gaussians, because we cannot directly visualise a 4D space.</p> <p>As an extension from the ellipse idea for 2D Gaussians, the set of 3D points which result in the same output from the 3D Gaussian function would lie on an <strong>ellipsoid</strong>. It can also be said that a 3D Gaussian is built from many ellipsoids where the larger ellipsoids enclose the smaller ones within them.</p> <p>Nonetheless, here’s an illustration of an ellipsoid just to have a mental picture:</p> <div class="row mt-3"> <div class="col-12 mx-auto mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/3dgs_blog/3D_Ellipsoid-480.webp 480w,/assets/img/3dgs_blog/3D_Ellipsoid-800.webp 800w,/assets/img/3dgs_blog/3D_Ellipsoid-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/3dgs_blog/3D_Ellipsoid.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> A 'slice' of a 3D Gaussian, an ellipsoid </div> <p>If we perform the eigenvalue decomposition of the $\Sigma$ matrix, we get:</p> \[\Sigma = Q \Lambda Q^\top\] <p>where:</p> <ul> <li>$Q$: A matrix whose columns are the <strong>eigenvectors defining orientation</strong> of the ellipsoid wrt to the $x$, $y$ and $z$ axes.</li> <li>$\Lambda$: A diagonal matrix containing <strong>eigenvalues defining stretching</strong> along the $x$, $y$ and $z$ axes.</li> </ul> <h2 id="key-idea">Key Idea</h2> <p>The general way to get <em>novel</em> view of any scene is to get a 3D representation of it, be it a mesh based, or point cloud based or a voxel based representation. Then using this 3D representation, render the scene from any viewpoint of your choice. This is basically like simulating the world (scene) inside our computers and then viewing it however we want.</p> <p>The problem is that these 3D representations of a scene cannot be reliably estimated from just a bunch of pictures of the scene. This is where the magic of 3D Gaussian Splatting comes in!</p> <p>Here, we represent the scene using 3D Gaussians. These Gaussians when projected and rendered on a 2D plane, give us a picture of the scene from a particular viewpoint. To be able to get a good picture of the scene from these Gaussians, the Gaussians are subjected to an interative optimization process. As part of the optimization process, we render the scene from the viewpoints for which we have the original images, and then take a photometric loss between the renderings and the original images.</p> <p>Based on the difference between the renderings and the original images, we tweak the properties (what are these properties?) of the 3D Gaussians such that their difference is minimised.</p> <div class="row mt-3"> <div class="col-12 mx-auto mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/3dgs_blog/3dgs_pipeline-480.webp 480w,/assets/img/3dgs_blog/3dgs_pipeline-800.webp 800w,/assets/img/3dgs_blog/3dgs_pipeline-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/3dgs_blog/3dgs_pipeline.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> The overall pipeline of the 3DGS framework </div> <h2 id="properties-of-a-3d-gaussian">Properties of a 3D Gaussian</h2> <p>The following are the properties attached with each of the 3D Gaussians in the 3DGS framework:</p> <ol> <li>3D position ($\boldsymbol{\mu}$): A 3D vector which signifies the exact location where the 3D Gaussian is placed in space.</li> <li>Opacity ($\alpha$): Gives how much of the colour of this Gaussian influences the final image. An opacity value of $0$ means that the Gaussian is completely transparent i.e. it does not contribute anything to the final image and an opacity value of $1$ means that the Gaussian is completely opaque i.e. nothing behind it is visible in the final image.</li> <li>Anisotropic covariance ($\Sigma$): This gives the scale (size) and rotation (orientation) of the 3D Gaussian. It is called anisotropic because it is not symmetric in the three directions. An isotropic covariance having 3D Gaussian will just be a sphere with varying size (here, $\Sigma = k\boldsymbol{I}$).</li> <li>SH coefficients: These give the colour of the 3D Gaussian as a function of the viewing direction.</li> </ol> <h2 id="projection-of-3d-gaussians-onto-a-2d-plane">Projection of 3D Gaussians onto a 2D plane</h2> <p>The 3DGS paper directly hands out the following relation between the covariance of the 3D Gaussian ($\Sigma_{3D}$) and the 2D Gaussian ($\Sigma_{2D}$) obtained after projection:</p> \[\begin{gathered} \Sigma_{2D} = JW \Sigma_{3D} W^{T}J^{T} \\ \text{(yes, this cannot be used directly)} \end{gathered}\] <p>We will now try to understand where this stems from instead of taking things just as given. Afterall, this is what researchers do!</p> <p>This part is a little more involved than what we have seen so far but hang on and we will get through it.</p> <p>An important property to know of about Gaussians is:</p> <div style="text-align:center; font-weight:bold;"> Gaussian functions are closed under affine transformations. </div> <p><br></p> <p>Let’s break down the above property step-by-step.</p> <p>Affine transformations are of the following form:</p> \[f(\vec{x}) = A\vec{x} + \vec{b}\] <p>And when Gaussian functions are subjected to an affine transformation, this again results in a Gaussian function. Hence, they are called closed under affine transformation.</p> <p>Don’t believe me? Here’s the proof for you.</p> <p>We re-write the affine transformation as: \(\vec{x} = A^{-1}(\vec{y} - \vec{b})\)</p> <p>Then we substitute this in the equation for 3D Gaussian:</p> \[\begin{align*} Q(\vec{y}) &amp;= \exp\left(-\frac{1}{2} \left(A^{-1}(\vec{y} - \vec{b}) - \vec{\mu}\right)^T \Sigma^{-1} \left(A^{-1}(\vec{y} - \vec{b}) - \vec{\mu}\right)\right) \\ &amp;= \exp\left(-\frac{1}{2} \left(A^{-1}(\vec{y} - (A\vec{\mu} + \vec{b}))\right)^T \Sigma^{-1} \left(A^{-1}(\vec{y} - (A\vec{\mu} + \vec{b}))\right)\right) \\ &amp;= \exp\left(-\frac{1}{2} \left(\vec{y} - {\color{blue}\underbrace{(A\vec{\mu} + \vec{b})}}\right)^T {\color{purple}\underbrace{A^{-T} \Sigma^{-1} A^{-1}}} \left(\vec{y} - {\color{blue}\underbrace{(A\vec{\mu} + \vec{b})}}\right)\right) \\ &amp;= \exp\left(-\frac{1}{2} (\vec{y} - {\color{blue}\vec{\mu}'})^T {\color{purple}\Sigma'} (\vec{y} - {\color{blue}\vec{\mu}'})\right) \end{align*}\] <p>See, even after applying the affine transformation, we end up with an equation for a Gaussian. Albeit with a different centre and covariance matrix (the transformation had to do something right?).</p> <p>You might remember seeing the following kind of illustration back in your computer vision class. This shows the need for world-to-camera coordinate system transformation.</p> <div class="row mt-3"> <div class="col-12 mx-auto mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/3dgs_blog/w2c-480.webp 480w,/assets/img/3dgs_blog/w2c-800.webp 800w,/assets/img/3dgs_blog/w2c-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/3dgs_blog/w2c.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Typical world-to-camera coordinate system transformation. </div> <p>To simplify our case of projecting 3D Gaussians onto a 2D plane, we will consider that there is no translation involved in going from the world coordinate system to the camera coordinate system and just a rotation gets the job done.</p> <p>We define the viewing transformation $W$ as the transformation which gets us from the world space to the camera space.</p> <p>Now, we apply the viewing transformation onto the 3D Gaussian function:</p> \[G(\vec{x}) = \exp\left\{-\frac{1}{2} (W\vec{x} - W\vec{\mu})^T (W\Sigma W^T)^{-1} (W\vec{x} - W\vec{\mu})\right\}\] <details><summary>How can we directly apply the viewing transformation on the covariance matrix? Isnt it meant for a point?</summary> <p>The covariance matrix is given as:</p> \[\Sigma = E[(\vec{x} - \vec{\mu})(\vec{x} - \vec{\mu})^{T}]\] <p>After applying the transformation $W$ on the vector $\vec{x}$:</p> \[\begin{align} \vec{x'} &amp;= W\vec{x} \\ \vec{\mu'} &amp;= W\vec{\mu} \end{align}\] <p>Now,</p> \[\begin{align*} \Sigma' &amp;= E\left[(\vec{x}' - \vec{\mu}')(\vec{x}' - \vec{\mu}')^T\right] \\ &amp;= E\left[(W(\vec{x} - \vec{\mu}))(W(\vec{x} - \vec{\mu}))^T\right] \\ &amp;= E\left[W(\vec{x} - \vec{\mu})(\vec{x} - \vec{\mu})^T W^T\right] \end{align*}\] <p>$W$ is a constant transformation matrix. Hence, can be directly taken out from the expectation expression.</p> \[\begin{align*} \Sigma' &amp;= W {\color{blue}{\underbrace{E\left[(\vec{x} - \vec{\mu})(\vec{x} - \vec{\mu})^T \right]}}} W^T \\ &amp;= W {\color{blue}\Sigma} W^{T} \\ \end{align*}\] <p>This justifies our application of the viewing transformation directly on the covariance matrix.</p> </details> <p>We now define the following terms in the <em>camera space</em> which will be come in handy in a while:</p> \[\begin{align*} \vec{x'} &amp;= W\vec{x} \\ \vec{\mu'} &amp;= W\vec{\mu} \\ \Sigma' &amp;= W \Sigma W^{T} \end{align*}\] <p>The Gaussians are to be projected in the camera space onto the $z=1$ plane, and the projection function $\varphi$ is defined as (<strong>cite the paper</strong>):</p> \[\varphi(\vec{x'}) = \vec{x'} (\vec{x_0}^{T} \vec{x'})^{-1} (\vec{x_0}^{T} \vec{x_0}) = \vec{x'} (\vec{x_0}^{T} \vec{x'})^{-1}\] <p>where $\vec{x_0} = [0, 0, 1]^{T}$ represents the projection of the camera space’s origin onto the $z=1$ plane.</p> <p>I myself don’t have an intuitive understanding of the above projection function but for the $z=1$ plane case, this gets simplified in a pretty understandable form:</p> \[\varphi(\vec{x}') = \vec{x'} \underbrace{ (\vec{x_0}^T \vec{x'})^{-1} }_{\substack{\downarrow \\ \frac{1}{Z}}} \underbrace{ (\vec{x_0}^T \vec{x_0}) }_{\substack{\downarrow \\ 1}}\] <p>And this is simply equivalent to:</p> \[\begin{bmatrix} x \\ y \\ z \end{bmatrix} \rightarrow \begin{bmatrix} x/z \\ y/z \\ 1 \end{bmatrix}\] <p>Another important property to take note of:</p> <div style="text-align:center; font-weight:bold;"> Gaussian functions are closed under affine transformations <span style="color: red;">but not under projective transformation</span>. </div> <p><br></p> <p>We want to get to get a 2D Gaussian after projection of 3D Gaussian onto the image plane. Hence, we take an affine approximation of the projection function using the Taylor’s series expansion:</p> \[\begin{align*} \varphi(\vec{x'}) &amp;= \varphi(\vec{\mu'}) + \frac{\partial\varphi}{\partial\vec{x'}}(\vec{\mu'})(\vec{x'} - \vec{\mu'}) + R_1(\vec{x'}) \\ &amp;\approx \varphi(\vec{\mu'}) + \frac{\partial\varphi}{\partial\vec{x'}}(\vec{\mu'})(\vec{x'} - \vec{\mu'}) \end{align*}\] <p>This gives us:</p> \[{\color{myPink} \varphi(\vec{x}') = \varphi(\vec{\mu}) + {J}(\vec{x}' - \vec{\mu}') }\] <p>where ${J} = \frac{\partial\varphi}{\partial\vec{x’}}(\vec{\mu’})$ is the Jacobian of the affine approximation of the projective transformation.</p> <p>Applying this approximated projection function to the 3D Gaussian’s function:</p> \[\begin{align*} G_{2D}(\vec{x'}) &amp;= \exp\left\{-\frac{1}{2} ({J}\vec{x'} - {J}\vec{\mu'})^T ({J} \Sigma' {J}^T)^{-1} ({J}\vec{x'} - {J}\vec{\mu'})\right\} \\ &amp;\approx \exp\left\{-\frac{1}{2} (\varphi(\vec{x'}) - \varphi(\vec{\mu'}))^T ({\color{purple}\underbrace{J \Sigma' {J}^T}_{\substack{\downarrow \\ \Sigma_{2D}}}})^{-1} (\varphi(\vec{x'}) - \varphi(\vec{\mu'}))\right\} \end{align*}\] <p>Comparing the above equation with that of a standard Gaussian equation, we get the relation for the covariance of the 2D Gaussian ($\Sigma_{2D}$).</p> \[\Sigma_{2D} = J \Sigma' {J}^T = J W \Sigma W^{T} J^{T}\] <p>Now, $\Sigma_{2D}$ must be a $2 \times 2$ matrix as it the covariance matrix of a <em>2D</em> Gaussian. However, the right hand side of the above equation gives out a $3 \times 3$ matrix.</p> <p>What’s at play here?</p> <p>If you have read the paper, you might know that we need to discard the last row and column of the obtained $3 \times 3$ matrix to get our desired $2 \times 2$ covariance matrix.</p> <p>Again, we cannot accept anything just because we were told so. Let’s try getting a better intuition for what’s going on.</p> <p>We have the following defined:</p> \[\begin{align*} \text{A point } \vec{x'} &amp;= [x, y, z]^T \\ \text{Gaussian's centre } \vec{\mu'} &amp;= [\mu_x, \mu_y, \mu_z]^T \\ \text{The projection formula } \varphi(\vec{x'}) &amp;= \begin{bmatrix} x/z \\ y/z \\ 1 \end{bmatrix} \end{align*}\] <p>The expanded Jacobian matrix would look like the following:</p> \[J = \frac{\partial \varphi}{\partial \vec{x'}}(\vec{\mu'}) = \begin{bmatrix} \frac{\partial(x/z)}{\partial x} &amp; \frac{\partial(x/z)}{\partial y} &amp; \frac{\partial(x/z)}{\partial z} \\ \frac{\partial(y/z)}{\partial x} &amp; \frac{\partial(y/z)}{\partial y} &amp; \frac{\partial(y/z)}{\partial z} \\ \frac{\partial(1)}{\partial x} &amp; \frac{\partial(1)}{\partial y} &amp; \frac{\partial(1)}{\partial z} \end{bmatrix}_{\text{at } \vec{x'}=\vec{\mu'}} = \begin{bmatrix} 1/\mu_z &amp; 0 &amp; -\mu_x/\mu_z^2 \\ 0 &amp; 1/\mu_z &amp; -\mu_y/\mu_z^2 \\ 0 &amp; 0 &amp; 0 \end{bmatrix}\] <p>Notice that the rank of the $J$ matrix is $2$ due to the third row being entirely zeros.</p> <p>Coming back,</p> \[\Sigma_{2D} = J \Sigma' J^{T} = \begin{bmatrix} 1/\mu_z &amp; 0 &amp; -\mu_x/\mu_z^2 \\ 0 &amp; 1/\mu_z &amp; -\mu_y/\mu_z^2 \\ 0 &amp; 0 &amp; 0 \end{bmatrix} \begin{bmatrix} \sigma'_{11} &amp; \sigma'_{12} &amp; \sigma'_{13} \\ \sigma'_{21} &amp; \sigma'_{22} &amp; \sigma'_{23} \\ \sigma'_{31} &amp; \sigma'_{32} &amp; \sigma'_{33} \end{bmatrix} \begin{bmatrix} 1/\mu_z &amp; 0 &amp; 0 \\ 0 &amp; 1/\mu_z &amp; 0 \\ -\mu_x/\mu_z^2 &amp; -\mu_y/\mu_z^2 &amp; 0 \end{bmatrix}\] \[\implies \Sigma_{2D} = J\Sigma'J^T = \begin{bmatrix} \sigma_{11} &amp; \sigma_{12} &amp; 0 \\ \sigma_{21} &amp; \sigma_{22} &amp; 0 \\ 0 &amp; 0 &amp; 0 \end{bmatrix}\] <p>$\Sigma_{2D}$ is the covariance matrix of the new shape in 3D space. But the zeros in the third row and column tell us that there is <em>zero covariance</em> in the 3rd dimension (the z-axis). This makes perfect sense, we flattened the Gaussian onto a 2D plane, so it has no ‘thickness’ or variation along the z-axis anymore. Hence, we can <em>skip the last row and column</em> to get our final $2 \times 2$ covariance matrix $\Sigma_{2D}$ for the 2D Gaussian.</p> <h2 id="way-forward">Way forward</h2> <p>We still haven’t covered some topics such as $\alpha$ blending and Spherical Harmonics. I myself am learning about these and will update the page when I have a good understanding of those. See you soon!</p> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/assets/bibliography/"></d-bibliography> </div> <footer class="sticky-bottom mt-5" role="contentinfo"> <div class="container"> © Copyright 2026 Parag Sarvoday Sahu. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/mermaid@10.7.0/dist/mermaid.min.js" integrity="sha256-TtLOdUA8mstPoO6sGvHIGx2ceXrrX4KgIItO06XOn8A=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/d3@7.8.5/dist/d3.min.js" integrity="sha256-1rA678n2xEx7x4cTZ5x4wpUCj6kUMZEZ5cxLSVSFWxw=" crossorigin="anonymous"></script> <script defer src="/assets/js/mermaid-setup.js?38ca0a0126f7328d2d9a46bad640931f" type="text/javascript"></script> <script src="https://cdn.jsdelivr.net/npm/diff2html@3.4.47/bundles/js/diff2html-ui.min.js" integrity="sha256-eU2TVHX633T1o/bTQp6iIJByYJEtZThhF9bKz/DcbbY=" crossorigin="anonymous"></script> <script defer src="/assets/js/diff2html-setup.js?80a6e52ce727518bbd3aed2bb6ba5601" type="text/javascript"></script> <script src="https://cdn.jsdelivr.net/npm/leaflet@1.9.4/dist/leaflet.min.js" integrity="sha256-MgH13bFTTNqsnuEoqNPBLDaqxjGH+lCpqrukmXc8Ppg=" crossorigin="anonymous"></script> <script defer src="/assets/js/leaflet-setup.js?b6313931e203b924523e2d8b75fe8874" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/chart.js@4.4.1/dist/chart.umd.min.js" integrity="sha256-0q+JdOlScWOHcunpUk21uab1jW7C1deBQARHtKMcaB4=" crossorigin="anonymous"></script> <script defer src="/assets/js/chartjs-setup.js?183c5859923724fb1cb3c67593848e71" type="text/javascript"></script> <script src="https://cdn.jsdelivr.net/npm/echarts@5.5.0/dist/echarts.min.js" integrity="sha256-QvgynZibb2U53SsVu98NggJXYqwRL7tg3FeyfXvPOUY=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/echarts@5.5.0/theme/dark-fresh-cut.js" integrity="sha256-sm6Ui9w41++ZCWmIWDLC18a6ki72FQpWDiYTDxEPXwU=" crossorigin="anonymous"></script> <script defer src="/assets/js/echarts-setup.js?738178999630746a8d0cfc261fc47c2c" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/vega@5.27.0/build/vega.min.js" integrity="sha256-Yot/cfgMMMpFwkp/5azR20Tfkt24PFqQ6IQS+80HIZs=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/vega-lite@5.16.3/build/vega-lite.min.js" integrity="sha256-TvBvIS5jUN4BSy009usRjNzjI1qRrHPYv7xVLJyjUyw=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/vega-embed@6.24.0/build/vega-embed.min.js" integrity="sha256-FPCJ9JYCC9AZSpvC/t/wHBX7ybueZhIqOMjpWqfl3DU=" crossorigin="anonymous"></script> <script defer src="/assets/js/vega-setup.js?7c7bee055efe9312afc861b128fe5f36" type="text/javascript"></script> <script defer src="https://tikzjax.com/v1/tikzjax.js" integrity="sha256-+1qyucCXRZJrCg3lm3KxRt/7WXaYhBid4/1XJRHGB1E=" crossorigin="anonymous"></script> <script src="/assets/js/typograms.js?062e75bede72543443762dc3fe36c7a5"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>